{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f92059a",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51182474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "BENCHMARK_SOURCE = \"benchmark_comprehensive.cpp\"\n",
    "BENCHMARK_EXECUTABLE = \"./benchmark_comprehensive\"\n",
    "TIMEOUT_SECONDS = 300  # 5 minutes max per algorithm\n",
    "\n",
    "print(\"‚úì Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af89509",
   "metadata": {},
   "source": [
    "## Step 2: Compile Benchmark (Run Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ffd420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the benchmark executable\n",
    "if not os.path.exists(BENCHMARK_EXECUTABLE) or \\\n",
    "   os.path.getmtime(BENCHMARK_SOURCE) > os.path.getmtime(BENCHMARK_EXECUTABLE):\n",
    "    print(\"Compiling benchmark...\")\n",
    "    result = subprocess.run(\n",
    "        [\"g++\", \"-o\", \"benchmark_comprehensive\", BENCHMARK_SOURCE,\n",
    "         \"-O3\", \"-std=c++17\", \"-march=native\", \"-fopenmp\"],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úì Compilation successful!\")\n",
    "    else:\n",
    "        print(f\"‚úó Compilation failed:\\n{result.stderr}\")\n",
    "else:\n",
    "    print(\"‚úì Benchmark already compiled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205793d",
   "metadata": {},
   "source": [
    "## Step 3: Select Dataset\n",
    "\n",
    "**Run this cell to see available datasets, then set your choice below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1352638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover all available datasets\n",
    "def get_graph_info(filepath):\n",
    "    \"\"\"Extract basic graph statistics from DIMACS file\"\"\"\n",
    "    vertices, edges = 0, 0\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.startswith('p '):\n",
    "                    parts = line.split()\n",
    "                    vertices = int(parts[2])\n",
    "                    edges = int(parts[3])\n",
    "                    break\n",
    "    except:\n",
    "        pass\n",
    "    density = (2 * edges) / (vertices * (vertices - 1)) * 100 if vertices > 1 else 0\n",
    "    return vertices, edges, density\n",
    "\n",
    "# Find all datasets\n",
    "dataset_folders = [\"datasets/real_world\", \"datasets/synthetic\", \"datasets/benchmark\"]\n",
    "all_datasets = []\n",
    "\n",
    "for folder in dataset_folders:\n",
    "    if os.path.exists(folder):\n",
    "        for f in glob.glob(f\"{folder}/*.txt\") + glob.glob(f\"{folder}/*.clq\"):\n",
    "            v, e, d = get_graph_info(f)\n",
    "            category = folder.split('/')[-1]\n",
    "            all_datasets.append({\n",
    "                'path': f,\n",
    "                'name': os.path.basename(f),\n",
    "                'category': category,\n",
    "                'vertices': v,\n",
    "                'edges': e,\n",
    "                'density': d\n",
    "            })\n",
    "\n",
    "# Sort by vertices (smallest first for faster demos)\n",
    "all_datasets.sort(key=lambda x: x['vertices'])\n",
    "\n",
    "print(f\"{'#':<3} {'Dataset':<35} {'Category':<12} {'V':>8} {'E':>10} {'Density':>8}\")\n",
    "print(\"=\"*80)\n",
    "for i, ds in enumerate(all_datasets):\n",
    "    print(f\"{i:<3} {ds['name']:<35} {ds['category']:<12} {ds['vertices']:>8} {ds['edges']:>10} {ds['density']:>7.2f}%\")\n",
    "\n",
    "print(f\"\\nüìä Total: {len(all_datasets)} datasets available\")\n",
    "print(\"\\nüí° Tip: Smaller graphs (low V) run faster. For presentations, try datasets with V < 500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101eea1c",
   "metadata": {},
   "source": [
    "## Step 4: Choose Your Dataset\n",
    "\n",
    "**Change the number below to select a dataset from the list above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680aba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "# ‚ïë  üëá CHANGE THIS NUMBER TO SELECT YOUR DATASET                              ‚ïë\n",
    "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "SELECTED_DATASET = 0  # <-- Enter the dataset number from the list above\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "if SELECTED_DATASET < 0 or SELECTED_DATASET >= len(all_datasets):\n",
    "    print(f\"‚ùå Invalid selection! Please choose a number between 0 and {len(all_datasets)-1}\")\n",
    "else:\n",
    "    selected = all_datasets[SELECTED_DATASET]\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìÅ SELECTED DATASET\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  Name:     {selected['name']}\")\n",
    "    print(f\"  Category: {selected['category']}\")\n",
    "    print(f\"  Path:     {selected['path']}\")\n",
    "    print(f\"  Vertices: {selected['vertices']:,}\")\n",
    "    print(f\"  Edges:    {selected['edges']:,}\")\n",
    "    print(f\"  Density:  {selected['density']:.2f}%\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Estimate runtime\n",
    "    if selected['vertices'] < 200:\n",
    "        est = \"< 30 seconds\"\n",
    "    elif selected['vertices'] < 500:\n",
    "        est = \"30 seconds - 2 minutes\"\n",
    "    elif selected['vertices'] < 1000:\n",
    "        est = \"2-5 minutes\"\n",
    "    else:\n",
    "        est = \"5+ minutes (some algorithms may timeout)\"\n",
    "    print(f\"\\n‚è±Ô∏è  Estimated Runtime: {est}\")\n",
    "    print(\"\\n‚úì Ready to run! Execute the next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab54e1c2",
   "metadata": {},
   "source": [
    "## Step 5: Run All 11 Algorithms\n",
    "\n",
    "**This cell runs all algorithms on the selected dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a40637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmark on selected dataset\n",
    "dataset_path = all_datasets[SELECTED_DATASET]['path']\n",
    "dataset_name = all_datasets[SELECTED_DATASET]['name']\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üöÄ RUNNING BENCHMARK: {dataset_name}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [BENCHMARK_EXECUTABLE, dataset_path],\n",
    "        capture_output=True, text=True,\n",
    "        timeout=TIMEOUT_SECONDS\n",
    "    )\n",
    "    \n",
    "    # Print output\n",
    "    print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(f\"Warnings: {result.stderr}\")\n",
    "        \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(f\"‚è∞ Benchmark timed out after {TIMEOUT_SECONDS} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "total_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"‚úì Total execution time: {total_time:.2f} seconds\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b528e33",
   "metadata": {},
   "source": [
    "## Step 6: Parse and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse results from stdout\n",
    "import re\n",
    "\n",
    "results = []\n",
    "lines = result.stdout.split('\\n') if result.returncode == 0 else []\n",
    "\n",
    "# Parse algorithm results\n",
    "for line in lines:\n",
    "    # Match pattern like: [1/11] Greedy Heuristic...    ‚úì Size:   8, Time:   0.000023 s\n",
    "    match = re.search(r'\\[(\\d+)/\\d+\\]\\s+(.+?)\\.{3}\\s+[‚úì‚úó]\\s+Size:\\s*(\\d+),\\s*Time:\\s*([\\d.]+)', line)\n",
    "    if match:\n",
    "        results.append({\n",
    "            'Algorithm': match.group(2).strip(),\n",
    "            'Clique Size': int(match.group(3)),\n",
    "            'Time (s)': float(match.group(4))\n",
    "        })\n",
    "    # Also check for SKIP or TIMEOUT\n",
    "    skip_match = re.search(r'\\[(\\d+)/\\d+\\]\\s+(.+?)\\.{3}\\s+SKIP', line)\n",
    "    if skip_match:\n",
    "        results.append({\n",
    "            'Algorithm': skip_match.group(2).strip(),\n",
    "            'Clique Size': 0,\n",
    "            'Time (s)': float('nan')\n",
    "        })\n",
    "\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    print(\"\\nüìä RESULTS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Find best results\n",
    "    max_clique = df['Clique Size'].max()\n",
    "    best_algos = df[df['Clique Size'] == max_clique]['Algorithm'].tolist()\n",
    "    fastest = df[df['Clique Size'] == max_clique].nsmallest(1, 'Time (s)')\n",
    "    \n",
    "    print(f\"\\nüèÜ Maximum Clique Size: {max_clique}\")\n",
    "    print(f\"   Found by: {', '.join(best_algos)}\")\n",
    "    if not fastest.empty:\n",
    "        print(f\"   Fastest optimal: {fastest.iloc[0]['Algorithm']} ({fastest.iloc[0]['Time (s)']:.6f}s)\")\n",
    "else:\n",
    "    print(\"No results parsed. Check the benchmark output above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e7100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "if results and len(df) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Filter out skipped algorithms\n",
    "    df_valid = df.dropna()\n",
    "    \n",
    "    # Color mapping: heuristics vs exact\n",
    "    heuristics = ['Greedy', 'Randomized', 'Simulated Annealing']\n",
    "    colors = ['#e74c3c' if any(h in algo for h in heuristics) else '#3498db' \n",
    "              for algo in df_valid['Algorithm']]\n",
    "    \n",
    "    # Plot 1: Execution Time\n",
    "    bars1 = axes[0].barh(df_valid['Algorithm'], df_valid['Time (s)'], color=colors, alpha=0.8)\n",
    "    axes[0].set_xlabel('Time (seconds)', fontsize=12)\n",
    "    axes[0].set_title(f'Execution Time - {dataset_name}', fontsize=14, fontweight='bold')\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add time labels\n",
    "    for bar, time in zip(bars1, df_valid['Time (s)']):\n",
    "        axes[0].text(bar.get_width(), bar.get_y() + bar.get_height()/2, \n",
    "                    f' {time:.4f}s', va='center', fontsize=9)\n",
    "    \n",
    "    # Plot 2: Clique Size\n",
    "    bars2 = axes[1].barh(df_valid['Algorithm'], df_valid['Clique Size'], color=colors, alpha=0.8)\n",
    "    axes[1].set_xlabel('Clique Size', fontsize=12)\n",
    "    axes[1].set_title(f'Clique Size Found - {dataset_name}', fontsize=14, fontweight='bold')\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add clique size labels\n",
    "    for bar, size in zip(bars2, df_valid['Clique Size']):\n",
    "        axes[1].text(bar.get_width(), bar.get_y() + bar.get_height()/2, \n",
    "                    f' {size}', va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#e74c3c', alpha=0.8, label='Heuristic (Approximate)'),\n",
    "        Patch(facecolor='#3498db', alpha=0.8, label='Exact (Optimal)')\n",
    "    ]\n",
    "    fig.legend(handles=legend_elements, loc='upper center', ncol=2, \n",
    "               bbox_to_anchor=(0.5, 1.02), fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.88)\n",
    "    plt.savefig(f'demo_results_{dataset_name.replace(\".\", \"_\")}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n‚úì Visualization saved as 'demo_results_{dataset_name.replace('.', '_')}.png'\")\n",
    "else:\n",
    "    print(\"No valid results to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e2c27d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Quick Reference\n",
    "\n",
    "### Recommended Datasets for Presentations\n",
    "\n",
    "| Speed | Datasets | Use Case |\n",
    "|-------|----------|----------|\n",
    "| ‚ö° Fast (< 30s) | Small R-MAT, p_hat300-1 | Quick demos |\n",
    "| üîÑ Medium (1-2 min) | email-Eu-core, brock200_* | Balanced |\n",
    "| üê¢ Slow (5+ min) | facebook_combined, twitter | Full capability demo |\n",
    "\n",
    "### Key Insights to Mention\n",
    "\n",
    "1. **Heuristics** (red bars) are fast but may find suboptimal cliques\n",
    "2. **Exact algorithms** (blue bars) guarantee optimal solutions\n",
    "3. **BBMC** is typically the fastest exact algorithm\n",
    "4. **Density matters**: High-density graphs are harder for exact algorithms"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
